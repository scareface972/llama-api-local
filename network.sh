#!/bin/bash

echo "üåê Informations R√©seau - API Llama.cpp"
echo "====================================="

# Couleurs pour l'affichage
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Fonction d'affichage avec couleur
print_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

print_header() {
    echo -e "${BLUE}[NETWORK]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

# D√©tection de l'adresse IP locale
print_header "Adresses IP disponibles :"
echo ""

# R√©cup√©ration de toutes les interfaces r√©seau
INTERFACES=$(ip addr show | grep -E "^[0-9]+:" | awk '{print $2}' | sed 's/://')

for interface in $INTERFACES; do
    # Ignorer les interfaces loopback et docker
    if [[ "$interface" != "lo" && "$interface" != "docker"* ]]; then
        IP=$(ip addr show $interface 2>/dev/null | grep -oP '(?<=inet\s)\d+(\.\d+){3}' | head -1)
        if [ ! -z "$IP" ]; then
            echo "Interface: $interface"
            echo "  IP: $IP"
            echo "  URL API: http://$IP:8000"
            echo "  URL Interface Web: http://$IP:8000"
            echo "  URL Documentation: http://$IP:8000/docs"
            echo ""
        fi
    fi
done

# V√©rification du statut du service
print_header "Statut du service :"
if systemctl is-active --quiet llama-api; then
    print_info "‚úÖ Service llama-api est ACTIF"
    print_info "üåê API accessible sur le r√©seau local"
else
    print_warning "‚ö†Ô∏è  Service llama-api n'est pas actif"
    print_info "D√©marrez le service avec : sudo systemctl start llama-api"
fi

# V√©rification du port
print_header "V√©rification du port 8000 :"
if netstat -tlnp 2>/dev/null | grep -q ":8000 "; then
    print_info "‚úÖ Port 8000 est ouvert et en √©coute"
    netstat -tlnp 2>/dev/null | grep ":8000 "
else
    print_warning "‚ö†Ô∏è  Port 8000 n'est pas en √©coute"
fi

# V√©rification du firewall
print_header "Configuration du firewall :"
if command -v ufw &> /dev/null; then
    if ufw status | grep -q "8000/tcp"; then
        print_info "‚úÖ Port 8000 autoris√© dans UFW"
    else
        print_warning "‚ö†Ô∏è  Port 8000 non autoris√© dans UFW"
        print_info "Autorisez avec : sudo ufw allow 8000/tcp"
    fi
else
    print_warning "UFW non install√© ou non configur√©"
fi

# Instructions d'acc√®s
echo ""
print_header "Instructions d'acc√®s :"
echo ""
echo "üì± Depuis un appareil sur le m√™me r√©seau :"
echo "   1. Connectez-vous au m√™me r√©seau WiFi/LAN"
echo "   2. Ouvrez un navigateur"
echo "   3. Tapez une des URLs ci-dessus"
echo ""
echo "üîß Exemple d'utilisation :"
echo "   ‚Ä¢ Interface Web: http://192.168.1.100:8000"
echo "   ‚Ä¢ API REST: http://192.168.1.100:8000/v1/chat/completions"
echo "   ‚Ä¢ Documentation: http://192.168.1.100:8000/docs"
echo "   ‚Ä¢ Health Check: http://192.168.1.100:8000/health"
echo ""

# Test de connectivit√©
print_header "Test de connectivit√© :"
echo "Testez la connectivit√© avec :"
echo "curl http://$(hostname -I | awk '{print $1}'):8000/health"
echo ""

# Informations de s√©curit√©
print_header "S√©curit√© :"
echo "‚ö†Ô∏è  IMPORTANT : L'API est accessible sur le r√©seau local"
echo "   ‚Ä¢ Assurez-vous que votre r√©seau est s√©curis√©"
echo "   ‚Ä¢ Changez le port si n√©cessaire dans config.py"
echo "   ‚Ä¢ Configurez un firewall appropri√©"
echo "   ‚Ä¢ Utilisez HTTPS en production"
echo ""

# Commandes utiles
print_header "Commandes utiles :"
echo "‚Ä¢ D√©marrer le service : sudo systemctl start llama-api"
echo "‚Ä¢ Arr√™ter le service : sudo systemctl stop llama-api"
echo "‚Ä¢ Voir les logs : sudo journalctl -u llama-api -f"
echo "‚Ä¢ Statut du service : sudo systemctl status llama-api"
echo "‚Ä¢ Ouvrir le port firewall : sudo ufw allow 8000/tcp"
echo "‚Ä¢ Voir les processus sur le port 8000 : sudo lsof -i :8000"
echo ""

print_info "üåê Votre API Llama.cpp est pr√™te pour l'acc√®s r√©seau local !" 