#!/bin/bash

echo "ğŸš€ DÃ©marrage de l'API Llama.cpp"
echo "=============================="

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fonction d'affichage avec couleur
print_status() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# VÃ©rification de l'utilisateur
if [ "$EUID" -eq 0 ]; then
    print_error "Ne pas exÃ©cuter ce script en tant que root"
    print_status "Utilisez un utilisateur normal"
    exit 1
fi

# VÃ©rification de l'environnement virtuel
if [ ! -d "venv" ]; then
    print_error "Environnement virtuel non trouvÃ©"
    print_status "ExÃ©cutez d'abord : ./install_clean.sh"
    exit 1
fi

# VÃ©rification du modÃ¨le
if [ ! -f "models/llama-2-7b-chat.gguf" ] && [ ! -f "models/llama-2-13b-chat.gguf" ] && [ ! -f "models/llama-2-7b.gguf" ] && [ ! -f "models/codellama-7b-instruct.gguf" ] && [ ! -f "models/mistral-7b-instruct.gguf" ]; then
    print_warning "Aucun modÃ¨le trouvÃ©"
    print_status "TÃ©lÃ©chargez un modÃ¨le avec : ./download_model.sh"
    echo ""
    read -p "Voulez-vous tÃ©lÃ©charger un modÃ¨le maintenant ? (y/N): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        ./download_model.sh
        if [ $? -ne 0 ]; then
            print_error "Ã‰chec du tÃ©lÃ©chargement du modÃ¨le"
            exit 1
        fi
    else
        print_status "DÃ©marrage sans modÃ¨le (le modÃ¨le devra Ãªtre tÃ©lÃ©chargÃ© manuellement)"
    fi
fi

# Activation de l'environnement virtuel
print_status "Activation de l'environnement virtuel..."
source venv/bin/activate

if [ -z "$VIRTUAL_ENV" ]; then
    print_error "Ã‰chec de l'activation de l'environnement virtuel"
    exit 1
fi

print_status "Environnement virtuel activÃ© : $VIRTUAL_ENV"

# VÃ©rification des dÃ©pendances
print_status "VÃ©rification des dÃ©pendances..."
python -c "
import sys
packages = ['fastapi', 'uvicorn', 'llama_cpp']
missing = []
for pkg in packages:
    try:
        __import__(pkg)
        print(f'âœ… {pkg} disponible')
    except ImportError:
        missing.append(pkg)
        print(f'âŒ {pkg} manquant')

if missing:
    print(f'\\nâŒ Packages manquants: {missing}')
    print('ExÃ©cutez : ./install_clean.sh')
    sys.exit(1)
else:
    print('\\nâœ… Toutes les dÃ©pendances sont disponibles')
"

if [ $? -ne 0 ]; then
    print_error "DÃ©pendances manquantes"
    exit 1
fi

# VÃ©rification du port
print_status "VÃ©rification du port 8000..."
if lsof -Pi :8000 -sTCP:LISTEN -t >/dev/null ; then
    print_warning "âš ï¸  Le port 8000 est dÃ©jÃ  utilisÃ©"
    read -p "Voulez-vous continuer quand mÃªme ? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        print_status "ArrÃªt du dÃ©marrage"
        exit 0
    fi
else
    print_status "âœ… Port 8000 disponible"
fi

# DÃ©marrage du serveur
print_status "DÃ©marrage du serveur..."
echo ""
print_status "ğŸŒ URLs d'accÃ¨s :"
echo "   â€¢ Interface Web : http://localhost:8000"
echo "   â€¢ Documentation API : http://localhost:8000/docs"
echo "   â€¢ Health Check : http://localhost:8000/health"
echo ""
print_status "ğŸ“‹ Commandes utiles :"
echo "   â€¢ ArrÃªter le serveur : Ctrl+C"
echo "   â€¢ Voir les logs : tail -f logs/llama_api.log"
echo "   â€¢ DÃ©marrer en service : sudo systemctl start llama-api"
echo ""

# DÃ©marrage avec uvicorn
python llama_api.py 