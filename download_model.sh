#!/bin/bash

echo "ğŸ“¥ TÃ©lÃ©chargement du modÃ¨le Llama.cpp optimisÃ©"
echo "=============================================="

# Configuration
MODEL_NAME="llama-2-7b-chat.gguf"
MODEL_URL="https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf"
MODELS_DIR="models"

# CrÃ©ation du rÃ©pertoire models s'il n'existe pas
mkdir -p $MODELS_DIR

# VÃ©rification si le modÃ¨le existe dÃ©jÃ 
if [ -f "$MODELS_DIR/$MODEL_NAME" ]; then
    echo "âœ… Le modÃ¨le existe dÃ©jÃ  dans $MODELS_DIR/$MODEL_NAME"
    echo "ğŸ“Š Taille du fichier: $(du -h $MODELS_DIR/$MODEL_NAME | cut -f1)"
    read -p "Voulez-vous le tÃ©lÃ©charger Ã  nouveau ? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "ğŸš€ Utilisation du modÃ¨le existant"
        exit 0
    fi
fi

echo "ğŸŒ TÃ©lÃ©chargement depuis Hugging Face..."
echo "ğŸ“¦ URL: $MODEL_URL"
echo "ğŸ’¾ Destination: $MODELS_DIR/$MODEL_NAME"
echo ""

# TÃ©lÃ©chargement avec wget avec barre de progression
if command -v wget &> /dev/null; then
    echo "ğŸ“¥ Utilisation de wget..."
    wget --progress=bar:force:noscroll -O "$MODELS_DIR/$MODEL_NAME" "$MODEL_URL"
elif command -v curl &> /dev/null; then
    echo "ğŸ“¥ Utilisation de curl..."
    curl -L -o "$MODELS_DIR/$MODEL_NAME" "$MODEL_URL"
else
    echo "âŒ Erreur: wget ou curl non trouvÃ©"
    exit 1
fi

# VÃ©rification du tÃ©lÃ©chargement
if [ -f "$MODELS_DIR/$MODEL_NAME" ]; then
    echo ""
    echo "âœ… TÃ©lÃ©chargement terminÃ© avec succÃ¨s !"
    echo "ğŸ“Š Taille du fichier: $(du -h $MODELS_DIR/$MODEL_NAME | cut -f1)"
    echo "ğŸ” VÃ©rification de l'intÃ©gritÃ©..."
    
    # VÃ©rification basique du fichier
    if file "$MODELS_DIR/$MODEL_NAME" | grep -q "data"; then
        echo "âœ… Fichier valide dÃ©tectÃ©"
    else
        echo "âš ï¸  Le fichier ne semble pas Ãªtre un modÃ¨le valide"
    fi
    
    echo ""
    echo "ğŸš€ Le modÃ¨le est prÃªt Ã  Ãªtre utilisÃ© !"
    echo "ğŸ“‹ Prochaines Ã©tapes :"
    echo "1. ExÃ©cutez : ./start_server.sh"
    echo "2. Ouvrez votre navigateur sur : http://localhost:8000"
    echo ""
    echo "ğŸ’¡ Informations sur le modÃ¨le :"
    echo "   â€¢ ModÃ¨le: Llama-2-7B-Chat"
    echo "   â€¢ Quantisation: Q4_K_M (optimisÃ© pour votre configuration)"
    echo "   â€¢ Taille: ~4GB (idÃ©al pour 8GB RAM + 4GB VRAM)"
    echo "   â€¢ Performance: Ã‰quilibrÃ©e entre vitesse et qualitÃ©"
    
else
    echo "âŒ Erreur lors du tÃ©lÃ©chargement"
    echo "ğŸ”§ Solutions possibles :"
    echo "   â€¢ VÃ©rifiez votre connexion internet"
    echo "   â€¢ Assurez-vous d'avoir suffisamment d'espace disque"
    echo "   â€¢ Essayez de tÃ©lÃ©charger manuellement depuis :"
    echo "     $MODEL_URL"
    exit 1
fi

echo ""
echo "ğŸ¯ Optimisations appliquÃ©es pour votre configuration :"
echo "   â€¢ CPU i5: Utilisation optimisÃ©e des cÅ“urs"
echo "   â€¢ GPU GTX 950M: 20 couches GPU activÃ©es"
echo "   â€¢ RAM 8GB: Gestion intelligente de la mÃ©moire"
echo "   â€¢ VRAM 4GB: Quantisation Q4_K_M optimale"
echo ""
echo "âœ¨ Votre IA locale est prÃªte !" 