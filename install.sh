#!/bin/bash

echo "üöÄ Installation compl√®te de l'API Llama.cpp optimis√©e pour Ubuntu"
echo "================================================================"

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fonction d'affichage avec couleur
print_status() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Fonction de v√©rification d'erreur
check_error() {
    if [ $? -ne 0 ]; then
        print_error "$1"
        exit 1
    fi
}

# V√©rification de l'utilisateur
if [ "$EUID" -eq 0 ]; then
    print_error "Ne pas ex√©cuter ce script en tant que root"
    print_status "Utilisez un utilisateur normal avec sudo"
    exit 1
fi

print_status "Utilisateur: $(whoami)"
print_status "R√©pertoire: $(pwd)"

# ============================================================================
# √âTAPE 1: MISE √Ä JOUR DU SYST√àME
# ============================================================================
print_status "√âTAPE 1: Mise √† jour du syst√®me..."
sudo apt update && sudo apt upgrade -y
check_error "√âchec de la mise √† jour du syst√®me"

# ============================================================================
# √âTAPE 2: INSTALLATION DES D√âPENDANCES SYST√àME
# ============================================================================
print_status "√âTAPE 2: Installation des d√©pendances syst√®me..."

# D√©pendances syst√®me essentielles (sans packages obsol√®tes)
sudo apt install -y \
    build-essential \
    cmake \
    git \
    wget \
    curl \
    python3 \
    python3-pip \
    python3-venv \
    libopenblas-dev \
    liblapack-dev \
    libatlas-base-dev \
    gfortran \
    libssl-dev \
    libffi-dev \
    libjpeg-dev \
    libpng-dev \
    libfreetype6-dev \
    libxft-dev \
    pkg-config \
    libhdf5-dev \
    libhdf5-serial-dev \
    libgtk-3-dev \
    libavcodec-dev \
    libavformat-dev \
    libswscale-dev \
    libv4l-dev \
    libxvidcore-dev \
    libx264-dev \
    libtiff-dev \
    libgstreamer1.0-dev \
    libgstreamer-plugins-base1.0-dev \
    libgtk2.0-dev \
    libtiff5-dev

check_error "√âchec de l'installation des d√©pendances syst√®me"

# ============================================================================
# √âTAPE 3: INSTALLATION DE CUDA (si GPU NVIDIA d√©tect√©)
# ============================================================================
print_status "√âTAPE 3: Configuration CUDA..."

if command -v nvidia-smi &> /dev/null; then
    print_status "‚úÖ GPU NVIDIA d√©tect√©, installation de CUDA..."
    
    # Installation des d√©pendances de base pour CUDA
    print_status "Installation des d√©pendances de base..."
    sudo apt install -y \
        build-essential \
        gcc \
        g++ \
        make \
        cmake \
        pkg-config
    check_error "√âchec de l'installation des d√©pendances de base"
    
    # Nettoyage des packages cass√©s
    print_status "Nettoyage des packages cass√©s..."
    sudo apt autoremove -y
    sudo apt autoclean
    sudo apt --fix-broken install -y
    check_error "√âchec de la r√©paration des packages"
    
    # Installation de CUDA Toolkit
    print_status "T√©l√©chargement de CUDA keyring..."
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
    check_error "√âchec du t√©l√©chargement de CUDA keyring"
    
    print_status "Installation de CUDA keyring..."
    sudo dpkg -i cuda-keyring_1.0-1_all.deb
    check_error "√âchec de l'installation de CUDA keyring"
    
    print_status "Mise √† jour des d√©p√¥ts..."
    sudo apt-get update
    check_error "√âchec de la mise √† jour des d√©p√¥ts"
    
    # Installation s√©lective de CUDA (sans nsight-systems qui pose probl√®me)
    print_status "Installation de CUDA toolkit (sans outils de d√©veloppement)..."
    sudo apt-get install -y cuda-runtime-12-0 cuda-libraries-12-0 --no-install-recommends
    if [ $? -ne 0 ]; then
        print_warning "Installation de base √©chou√©e, tentative d'installation minimale..."
        sudo apt-get install -y cuda-compiler-12-0 cuda-libraries-12-0
        check_error "√âchec de l'installation minimale de CUDA"
    fi
    
    # Configuration des variables d'environnement CUDA
    print_status "Configuration des variables d'environnement CUDA..."
    if [ -d "/usr/local/cuda-12.0" ]; then
        echo 'export PATH=/usr/local/cuda-12.0/bin:$PATH' >> ~/.bashrc
        echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.0/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
        source ~/.bashrc
        print_status "‚úÖ CUDA install√© et configur√©"
    else
        print_warning "‚ö†Ô∏è  CUDA install√© mais r√©pertoire non trouv√©, configuration manuelle n√©cessaire"
    fi
else
    print_warning "‚ö†Ô∏è  GPU NVIDIA non d√©tect√©, installation sans CUDA"
fi

# ============================================================================
# √âTAPE 4: INSTALLATION DE LLAMA.CPP
# ============================================================================
print_status "√âTAPE 4: Installation de llama.cpp..."

# Suppression de l'ancienne installation si elle existe
if [ -d "llama.cpp" ]; then
    print_warning "llama.cpp existe d√©j√†, suppression..."
    rm -rf llama.cpp
fi

# Clonage de llama.cpp
git clone https://github.com/ggerganov/llama.cpp.git
check_error "√âchec du clonage de llama.cpp"

cd llama.cpp

# Compilation optimis√©e pour votre configuration
print_status "Compilation optimis√©e pour i5 + GTX 950M..."
make clean

# Compilation avec optimisations CUDA si disponible
if command -v nvidia-smi &> /dev/null; then
    make LLAMA_CUBLAS=1 LLAMA_AVX=1 LLAMA_AVX2=1 LLAMA_F16C=1 LLAMA_FMA=1 LLAMA_BLAS=1 LLAMA_OPENBLAS=1 -j$(nproc)
else
    make LLAMA_AVX=1 LLAMA_AVX2=1 LLAMA_F16C=1 LLAMA_FMA=1 LLAMA_BLAS=1 LLAMA_OPENBLAS=1 -j$(nproc)
fi

check_error "√âchec de la compilation de llama.cpp"

# Retour au r√©pertoire principal
cd ..

# ============================================================================
# √âTAPE 5: CR√âATION DE L'ENVIRONNEMENT VIRTUEL PYTHON
# ============================================================================
print_status "√âTAPE 5: Configuration de l'environnement Python..."

# Suppression de l'ancien environnement si il existe
if [ -d "venv" ]; then
    print_warning "Environnement virtuel existe d√©j√†, suppression..."
    rm -rf venv
fi

# Cr√©ation d'un nouvel environnement virtuel
python3 -m venv venv
check_error "√âchec de la cr√©ation de l'environnement virtuel"

# Activation de l'environnement virtuel
source venv/bin/activate
check_error "√âchec de l'activation de l'environnement virtuel"

# V√©rification que l'environnement est activ√©
if [ -z "$VIRTUAL_ENV" ]; then
    print_error "L'environnement virtuel n'est pas activ√©"
    exit 1
fi

print_status "Environnement virtuel activ√© : $VIRTUAL_ENV"

# ============================================================================
# √âTAPE 6: INSTALLATION DES D√âPENDANCES PYTHON
# ============================================================================
print_status "√âTAPE 6: Installation des d√©pendances Python..."

# Mise √† jour de pip
python -m pip install --upgrade pip
check_error "√âchec de la mise √† jour de pip"

# Installation des d√©pendances de base
python -m pip install --upgrade setuptools wheel
check_error "√âchec de l'installation de setuptools/wheel"

# Installation s√©quentielle des d√©pendances (pour √©viter les conflits)
print_status "Installation s√©quentielle des d√©pendances..."

# 1. Numpy (base pour beaucoup d'autres packages)
print_status "1. Installation de numpy..."
python -m pip install "numpy>=1.24.0"
check_error "√âchec de l'installation de numpy"

# 2. FastAPI et Uvicorn
print_status "2. Installation de FastAPI et Uvicorn..."
python -m pip install "fastapi>=0.104.1" "uvicorn[standard]>=0.24.0"
check_error "√âchec de l'installation de FastAPI/Uvicorn"

# 3. Pydantic
print_status "3. Installation de Pydantic..."
python -m pip install "pydantic>=2.5.0"
check_error "√âchec de l'installation de Pydantic"

# 4. Autres d√©pendances web
print_status "4. Installation des d√©pendances web..."
python -m pip install "python-multipart>=0.0.6" "jinja2>=3.1.2" "aiofiles>=23.2.1" "websockets>=12.0"
check_error "√âchec de l'installation des d√©pendances web"

# 5. Psutil
print_status "5. Installation de psutil..."
python -m pip install "psutil>=5.9.6"
check_error "√âchec de l'installation de psutil"

# 6. PyTorch (s√©par√© car peut √™tre long)
print_status "6. Installation de PyTorch..."
if command -v nvidia-smi &> /dev/null; then
    python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
else
    python -m pip install torch torchvision torchaudio
fi
check_error "√âchec de l'installation de PyTorch"

# 7. Transformers et d√©pendances
print_status "7. Installation de Transformers..."
python -m pip install "transformers>=4.36.0" "sentencepiece>=0.1.99" "accelerate>=0.25.0"
check_error "√âchec de l'installation de Transformers"

# 8. Llama-cpp-python (avec fallback automatique)
print_status "8. Installation de llama-cpp-python..."
if command -v nvidia-smi &> /dev/null; then
    # Tentative d'installation depuis le d√©p√¥t personnalis√©
    if python -m pip install llama-cpp-python --index-url https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/AVX2/cu118 2>/dev/null; then
        print_status "‚úÖ llama-cpp-python install√© depuis le d√©p√¥t personnalis√©"
    else
        print_warning "√âchec du d√©p√¥t personnalis√©, compilation CUDA..."
        export CMAKE_ARGS="-DLLAMA_CUBLAS=on"
        export FORCE_CMAKE=1
        python -m pip install llama-cpp-python --no-cache-dir
        check_error "√âchec de l'installation de llama-cpp-python avec CUDA"
    fi
else
    # Installation sans CUDA
    python -m pip install llama-cpp-python --no-cache-dir
    check_error "√âchec de l'installation de llama-cpp-python"
fi

# ============================================================================
# √âTAPE 7: CR√âATION DE LA STRUCTURE DU PROJET
# ============================================================================
print_status "√âTAPE 7: Cr√©ation de la structure du projet..."
mkdir -p models
mkdir -p logs
mkdir -p static
mkdir -p templates
mkdir -p config

# ============================================================================
# √âTAPE 8: CONFIGURATION DES PERMISSIONS
# ============================================================================
print_status "√âTAPE 8: Configuration des permissions..."
chmod +x *.sh
chmod +x llama_api.py
chmod +x config.py

# ============================================================================
# √âTAPE 9: CONFIGURATION DU DAEMON SYSTEMD
# ============================================================================
print_status "√âTAPE 9: Configuration du daemon systemd..."

# V√©rification de l'existence du fichier service
if [ ! -f "llama-api.service" ]; then
    print_error "Fichier llama-api.service non trouv√©"
    exit 1
fi

# D√©tection de l'utilisateur et du chemin
CURRENT_USER=$(whoami)
CURRENT_GROUP=$(id -gn)
PROJECT_PATH=$(pwd)

print_status "Utilisateur: $CURRENT_USER"
print_status "Groupe: $CURRENT_GROUP"
print_status "Chemin du projet: $PROJECT_PATH"

# Mise √† jour du fichier service avec les bonnes informations
sed -i "s|User=ubuntu|User=$CURRENT_USER|g" llama-api.service
sed -i "s|Group=ubuntu|Group=$CURRENT_GROUP|g" llama-api.service
sed -i "s|/home/ubuntu/llama-api-local|$PROJECT_PATH|g" llama-api.service

# Copie du fichier service vers systemd
sudo cp llama-api.service /etc/systemd/system/
check_error "√âchec de la copie du fichier service"

# Rechargement de systemd
sudo systemctl daemon-reload
check_error "√âchec du rechargement de systemd"

# Activation du service
sudo systemctl enable llama-api.service
check_error "√âchec de l'activation du service"

print_status "‚úÖ Service systemd configur√© et activ√©"

# ============================================================================
# √âTAPE 10: CONFIGURATION DU FIREWALL
# ============================================================================
print_status "√âTAPE 10: Configuration du firewall..."
if command -v ufw &> /dev/null; then
    sudo ufw allow 8000/tcp
    print_status "‚úÖ Port 8000 ouvert dans le firewall"
else
    print_warning "UFW non install√©, configurez manuellement le port 8000"
fi

# ============================================================================
# √âTAPE 11: INSTALLATION DES OUTILS DE SURVEILLANCE
# ============================================================================
print_status "√âTAPE 11: Installation des outils de surveillance..."
sudo apt install -y htop iotop nvtop

# ============================================================================
# √âTAPE 12: V√âRIFICATION FINALE
# ============================================================================
print_status "√âTAPE 12: V√©rification finale..."

# V√©rification de l'environnement virtuel
if [ -d "venv" ] && [ -f "venv/bin/activate" ]; then
    print_status "‚úÖ Environnement virtuel cr√©√©"
else
    print_error "‚ùå Environnement virtuel manquant"
    exit 1
fi

# V√©rification de llama.cpp
if [ -d "llama.cpp" ] && [ -f "llama.cpp/main" ]; then
    print_status "‚úÖ llama.cpp compil√©"
else
    print_error "‚ùå llama.cpp manquant ou non compil√©"
    exit 1
fi

# V√©rification des d√©pendances Python
source venv/bin/activate
python -c "
import sys
packages = ['fastapi', 'uvicorn', 'pydantic', 'numpy', 'torch', 'transformers', 'llama_cpp']
missing = []
for pkg in packages:
    try:
        __import__(pkg)
        print(f'‚úÖ {pkg} install√©')
    except ImportError:
        missing.append(pkg)
        print(f'‚ùå {pkg} manquant')

if missing:
    print(f'\\n‚ùå Packages manquants: {missing}')
    sys.exit(1)
else:
    print('\\n‚úÖ Toutes les d√©pendances sont install√©es')
"

if [ $? -eq 0 ]; then
    print_status "‚úÖ Installation termin√©e avec succ√®s !"
else
    print_error "‚ùå Certaines d√©pendances sont manquantes"
    exit 1
fi

# ============================================================================
# FINALISATION
# ============================================================================
echo ""
echo "üéâ INSTALLATION TERMIN√âE AVEC SUCC√àS !"
echo "======================================"
echo ""
echo "üìã Prochaines √©tapes :"
echo "1. T√©l√©charger le mod√®le : ./download_model.sh"
echo "2. Tester le serveur : ./start_server.sh"
echo "3. Ou d√©marrer le service : sudo systemctl start llama-api"
echo "4. V√©rifier le statut : sudo systemctl status llama-api"
echo "5. Voir les logs : sudo journalctl -u llama-api -f"
echo "6. Acc√®s r√©seau : ./network-info.sh"
echo ""
echo "üåê URLs d'acc√®s :"
echo "   ‚Ä¢ Interface Web : http://localhost:8000"
echo "   ‚Ä¢ Documentation API : http://localhost:8000/docs"
echo "   ‚Ä¢ Health Check : http://localhost:8000/health"
echo ""
echo "üîß Commandes utiles :"
echo "   ‚Ä¢ D√©marrer : sudo systemctl start llama-api"
echo "   ‚Ä¢ Arr√™ter : sudo systemctl stop llama-api"
echo "   ‚Ä¢ Red√©marrer : sudo systemctl restart llama-api"
echo "   ‚Ä¢ Statut : sudo systemctl status llama-api"
echo "   ‚Ä¢ Logs : sudo journalctl -u llama-api -f"
echo ""
echo "üìä Surveillance :"
echo "   ‚Ä¢ Monitoring : ./monitor.sh"
echo "   ‚Ä¢ Diagnostic : ./diagnose_env.sh"
echo "   ‚Ä¢ R√©paration : ./fix_venv.sh"
echo ""
echo "üéØ Votre API Llama.cpp est pr√™te !" 